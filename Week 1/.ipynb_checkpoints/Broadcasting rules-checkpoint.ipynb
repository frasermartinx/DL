{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reading will introduce you to numpy's broadcasting rules and show how you can use broadcasting with TensorFlow Tensors and Variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 12:33:15.886260: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on arrays of different sizes in numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy operations can be applied to arrays that are not of the same shape, but only if the shapes satisfy certain conditions.\n",
    "\n",
    "As a demonstration of this, let us add together two arrays of different shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [2., 3., 4.],\n",
       "       [3., 4., 5.],\n",
       "       [4., 5., 6.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add two arrays with different shapes\n",
    "\n",
    "a = np.array([[1.],\n",
    "              [2.],\n",
    "              [3.],\n",
    "              [4.]])  # shape (4, 1)\n",
    "\n",
    "b = np.array([0., 1., 2.])  # shape (3,) \n",
    "\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the addition\n",
    "\n",
    "    [ [1.],    +  [0., 1., 2.]  \n",
    "      [2.],  \n",
    "      [3.],  \n",
    "      [4.] ]\n",
    "\n",
    "To execute it, numpy:\n",
    "1. Aligned the shapes of `a` and `b` on the last axis and prepended 1s to the shape with fewer axes:\n",
    "        a:     3     --->    a: 1 x 3\n",
    "        b: 4 x 1     --->    b: 4 x 1\n",
    "        \n",
    "\n",
    "2. Checked that the sizes of the axes matched or were equal to 1:\n",
    "        a: 1 x 3  \n",
    "        b: 4 x 1\n",
    "`a` and `b` satisfied this criterion. \n",
    "\n",
    "\n",
    "3. Stretched both arrays on their 1-valued axes so that their shapes matched, then added them together.  \n",
    "`a` was replicated 4 times in the first axis, while `b` was replicated 3 times in the second axis.\n",
    "\n",
    "This meant that the addition in the final step was\n",
    "\n",
    "    [ [1., 1., 1.],    +  [ [0., 1., 2.],  \n",
    "      [2., 2., 2.],         [0., 1., 2.],  \n",
    "      [3., 3., 3.],         [0., 1., 2.],  \n",
    "      [4., 4., 4.] ]        [0., 1., 2.] ]\n",
    "      \n",
    "Addition was then carried out element-by-element, as you can verify by referring back to the output of the code cell above.  \n",
    "This resulted in an output with shape 4 x 3.\n",
    "\n",
    "\n",
    "## Numpy's broadcasting rule\n",
    "\n",
    "Broadcasting rules describe how values should be transmitted when the inputs to an operation do not match.  \n",
    "In numpy, the broadcasting rule is very simple:\n",
    "> Prepend 1s to the smaller shape,   \n",
    "check that the axes of both arrays have sizes that are equal or 1,  \n",
    "then stretch the arrays in their size-1 axes.\n",
    "\n",
    "A crucial aspect of this rule is that it does not require the input arrays have the same number of axes.  \n",
    "Another consequence of it is that a broadcasting output will have the largest size of its inputs in each axis.  \n",
    "Take the following multiplication as an example:\n",
    "\n",
    "        a: 3 x 7 x 1  \n",
    "        b:     1 x 5  \n",
    "    a * b: 3 x 7 x 5\n",
    "\n",
    "You can see that the output shape is the maximum of the sizes in each axis.\n",
    "\n",
    "Numpy's broadcasting rule also does not require that one of the arrays has to be bigger in all axes.  \n",
    "This is seen in the following example, where `a` is smaller than `b` in its third axis but is bigger in its second axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.e-02, 2.e-02],\n",
       "        [2.e-01, 2.e-01]],\n",
       "\n",
       "       [[3.e+00, 3.e+00],\n",
       "        [3.e+01, 3.e+01]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply two arrays with different shapes\n",
    "\n",
    "a = np.array([[[0.01], [0.1]],\n",
    "              [[1.00], [10.]]])  # shape (2, 2, 1)\n",
    "b = np.array([[[2., 2.]],\n",
    "              [[3., 3.]]])       # shape (2, 1, 2)\n",
    "\n",
    "a * b #Â shape (2, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting behaviour also points to an efficient way to compute an outer product in numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0., -1., -2., -3.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  2.,  3.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use broadcasting to compute an outer product\n",
    "\n",
    "a = np.array([-1., 0., 1.])\n",
    "b = np.array([0., 1., 2., 3.])\n",
    "\n",
    "a[:, np.newaxis] * b  # outer product ab^T, where a and b are column vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of numpy stretching the arrays in their size-1 axes is useful and is functionally correct. But this is not what numpy literally does behind the scenes, since that would be an inefficient use of memory. Instead, numpy carries out the operation by looping over singleton (size-1) dimensions.\n",
    "\n",
    "To give you some practise with broadcasting, try predicting the output shapes for the following operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three arrays with different shapes\n",
    "\n",
    "a = [[1.], [2.], [3.]]\n",
    "b = np.zeros(shape=[10, 1, 1])\n",
    "c = np.ones(shape=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the shape before executing this cell\n",
    "\n",
    "(a + b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the shape before executing this cell\n",
    "\n",
    "(a*c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the shape before executing this cell\n",
    "\n",
    "(a*b + c).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting with TensorFlow Tensors and Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The broadcasting rule for TensorFlow is the same as that for numpy, and broadcasting can be used in operations on Tensors and Variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 12:38:27.470273: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [2., 3., 4.],\n",
       "       [3., 4., 5.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add two Tensors with different shapes\n",
    "\n",
    "a = tf.constant([[1.],\n",
    "                 [2.],\n",
    "                 [3.],\n",
    "                 [4.]])  # shape (4, 1)\n",
    "\n",
    "b = tf.constant([0., 1., 2.])  # shape (3,) \n",
    "\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[2.e-02, 2.e-02],\n",
       "        [2.e-01, 2.e-01]],\n",
       "\n",
       "       [[3.e+00, 3.e+00],\n",
       "        [3.e+01, 3.e+01]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply two Tensors with different shapes\n",
    "\n",
    "a = tf.constant([[[0.01], [0.1]],\n",
    "                 [[1.00], [10.]]])  # shape (2, 2, 1)\n",
    "b = tf.constant([[[2., 2.]],\n",
    "                 [[3., 3.]]])       # shape (2, 1, 2)\n",
    "\n",
    "a * b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[-0., -1., -2., -3.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  2.,  3.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use broadcasting to compute an outer product\n",
    "\n",
    "a = tf.Variable([-1., 0., 1.])\n",
    "b = tf.Variable([0., 1., 2., 3.])\n",
    "\n",
    "a[:, tf.newaxis] * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further reading and resources\n",
    "* Numpy documentation on broadcasting: https://numpy.org/devdocs/user/theory.broadcasting.html\n",
    "* https://www.tensorflow.org/xla/broadcasting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
