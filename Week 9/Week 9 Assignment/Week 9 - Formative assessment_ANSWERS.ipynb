{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "## Formative assessment\n",
    "### Week 9: Normalising flows II: NICE, RealNVP & Glow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "\n",
    "In this notebook, you will write code to implement a complete RealNVP normalising flow model, including checkerboard and channel-wise masking, and combining all the components into a multiscale architecture. You will train the normalising flow on the CIFAR-10 dataset.\n",
    "\n",
    "Some code cells are provided you in the notebook. You should avoid editing provided code, and make sure to execute the cells in order to avoid unexpected errors. Some cells begin with the line: \n",
    "\n",
    "`#### GRADED CELL ####`\n",
    "\n",
    "These cells require you to write your own code to complete them.\n",
    "\n",
    "#### Let's get started!\n",
    "\n",
    "We'll start by running some imports, and loading the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PACKAGE IMPORTS ####\n",
    "\n",
    "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# If you would like to make further imports from Tensorflow, add them here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cifar10.png\" title=\"CIFAR-10\" style=\"width: 700px;\"/> \n",
    "\n",
    "#### The CIFAR-10 dataset\n",
    "In this assignment, you will use the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). This image dataset has 60,000 32x32 colour images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. \n",
    "\n",
    "* A. Krizhevsky (2009), \"Learning Multiple Layers of Features from Tiny Images\", technical report.\n",
    "\n",
    "Your goal is to develop a RealNVP normalising flow generative model, trained on this dataset. This assignment will roughly follow the architecture described in the original RealNVP paper:\n",
    "\n",
    "* Dinh, L., Sohl-Dickstein, J. & Bengio, S. (2017), \"Density estimation using Real NVP\",  in *5th International Conference on Learning Representations, (ICLR)*, Toulon, France, April 24-26, 2017.\n",
    "\n",
    "An important conceptual point to bear in mind during the course of this assignment, is that we also follow the original paper by thinking of the forward transformation as acting on the input image. Note that this is in contrast to the convention for bijectors of using the forward transformation for sampling, and the inverse transformation for computing log probs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from tf.keras.datasets\n",
    "\n",
    "(images_train, labels_train), (images_val, labels_val) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list for the labels\n",
    "\n",
    "word_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few images and labels\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "inx = np.random.choice(images_train.shape[0], 32, replace=False)\n",
    "for n, i in enumerate(inx):\n",
    "    ax = plt.subplot(4, 8, n+1)\n",
    "    plt.imshow(images_train[i])\n",
    "    plt.title(word_labels[int(labels_train[i])])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now write a `get_datasets` function to load the data into `tf.data.Dataset` objects, and preprocess the data ready for training.\n",
    "\n",
    "* The function takes arguments `images_train`, `images_val`, `shuffle_buffer` and `batch_size`\n",
    "* Create two Datasets, one for training and one for validation\n",
    "* Only the images should be loaded into the Datasets; the labels will not be used\n",
    "* Your function should convert the image dtype to `tf.float32`, rescale so the pixel values lie in the range `[0, 1]`, and repeat the image for both inputs and targets\n",
    "* The function should then shuffle the training Dataset using the `shuffle_buffer` argument\n",
    "* It should then batch both Datasets using the `batch_size` argument\n",
    "* Your function should end with a call to `prefetch` (using the argument `tf.data.AUTOTUNE`) and return both Datasets in a tuple `(train_ds, valid_ds)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function.\n",
    "# Make sure not to change the function name or arguments.\n",
    "\n",
    "def get_datasets(images_train, images_val, shuffle_buffer, batch_size):\n",
    "    \"\"\"\n",
    "    This function takes the training and validation images, as well as shuffle_buffer\n",
    "    and batch_size arguments. It should load and preprocess the data as specified above.\n",
    "    Your function should then return the Datasets in the tuple (train_ds, valid_ds)\n",
    "    \"\"\"\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(images_train)\n",
    "    valid_ds = tf.data.Dataset.from_tensor_slices(images_val)\n",
    "    \n",
    "    def map_dataset(img):\n",
    "        img = tf.cast(img, tf.float32)\n",
    "        img = img / 255.\n",
    "        return img, img\n",
    "    \n",
    "    train_ds = train_ds.map(map_dataset)\n",
    "    valid_ds = valid_ds.map(map_dataset)\n",
    "    \n",
    "    train_ds = train_ds.shuffle(shuffle_buffer)\n",
    "    \n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    valid_ds = valid_ds.batch(batch_size)\n",
    "    \n",
    "    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    valid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to create the Datasets\n",
    "\n",
    "shuffle_buffer = 500\n",
    "batch_size = 64\n",
    "train_ds, valid_ds = get_datasets(images_train, images_val, shuffle_buffer, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom model for log-scale and shift\n",
    "Recall the equations for the affine coupling layer:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\left. \n",
    "\\begin{array}{rcl}\n",
    "\\mathbf{z}_{1:d} &= &\\mathbf{x}_{1:d},\\\\\n",
    "\\mathbf{z}_{d+1:D} &=& \\mathbf{x}_{d+1:D}\\odot \\exp(s(\\mathbf{x}_{1:d})) + t(\\mathbf{x}_{1:d}).\n",
    "\\end{array}\n",
    "\\right\\}\\qquad\\text{forward pass}\n",
    "\\\\[1ex]\n",
    "\\left. \n",
    "\\begin{array}{rcl}\n",
    "\\mathbf{x}_{1:d} &=& \\mathbf{z}_{1:d},\\label{realnvp_inv_acl1}\\\\\n",
    "\\mathbf{x}_{d+1:D} &=& (\\mathbf{z}_{d+1:D} - t(\\mathbf{z}_{1:d})) \\odot \\exp(-s(\\mathbf{z}_{1:d})).\n",
    "\\end{array}\n",
    "\\right\\}\\qquad\\text{inverse pass}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We will use a custom CNN residual network model for the shift and log-scale parameters that are used in this layer bijector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now complete the following class to create a custom layer as the residual block for use in this custom model. \n",
    "\n",
    "* The class initializer takes `num_filters`, `kernel_size` and `l2reg_coeff` arguments, and optional keyword arguments\n",
    "  * Any keyword arguments should be passed up to the base class initializer\n",
    "  * The required arguments should be set as class attributes, to be available to other methods\n",
    "* The class should implement a `build` method, that creates the model layers\n",
    "  * There should be two `Conv2D` layers. The first has `num_filters` filters, and the second has the same number of filters as the layer inputs\n",
    "  * Both `Conv2D` layers should use the `kernel_size` argument to set the kernel size, and should use a ReLU activation and `\"SAME\"` padding\n",
    "  * Both `Conv2D` layers should also use $l^2$ kernel regularisation, using the `l2reg_coeff` argument\n",
    "  * This method should also create two `BatchNormalization` layers\n",
    "* In the `call` method, the layer inputs should be processed as follows:\n",
    "  * First, the inputs are passed through the first `Conv2D` layer (with `num_filters` filters)\n",
    "  * Then they are passed through a `BatchNormalization` layer\n",
    "  * Then they are processed by the other `Conv2D` layer, and then the other `BatchNormalization` layer\n",
    "  * Finally, this output should then be added to the original layer input and returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following class. \n",
    "# Make sure to not change the class name or provided methods and signatures.\n",
    "\n",
    "class Conv2DResidualBlock(Layer):\n",
    "    \n",
    "    def __init__(self, num_filters, kernel_size, l2reg_coeff, **kwargs):\n",
    "        \"\"\"\n",
    "        Class initializer takes kernel_size num_filters and l2reg_coeff as arguments, and \n",
    "        optional keyword arguments that should be passed to the base Layer class initializer.\n",
    "        \"\"\"\n",
    "        super(Conv2DResidualBlock, self).__init__(**kwargs)\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.l2reg_coeff = l2reg_coeff\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_filters = input_shape[-1]\n",
    "        self.conv_1 = Conv2D(self.num_filters, kernel_size=self.kernel_size, padding=\"SAME\",\n",
    "                            activation='relu', kernel_regularizer=l2(self.l2reg_coeff), input_shape=input_shape)\n",
    "        self.bn_1 = BatchNormalization()\n",
    "        self.conv_2 = Conv2D(input_filters, kernel_size=self.kernel_size, padding=\"SAME\",\n",
    "                            activation='relu', kernel_regularizer=l2(self.l2reg_coeff))\n",
    "        self.bn_2 = BatchNormalization()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        h = self.conv_1(inputs)\n",
    "        h = self.bn_1(h)\n",
    "        h = self.conv_2(h)\n",
    "        h = self.bn_2(h)\n",
    "        return h + inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create residual block layers using your class\n",
    "\n",
    "resnet_block1 = Conv2DResidualBlock(64, (3, 3), 5e-5, name='resnet1')\n",
    "resnet_block2 = Conv2DResidualBlock(64, (3, 3), 5e-5, name='resnet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and call the first residual block\n",
    "\n",
    "resnet_block1(tf.random.normal((1, 32, 32, 3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and call the second residual block\n",
    "\n",
    "resnet_block2(tf.random.normal((1, 32, 32, 3))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now complete the following `get_shift_and_log_scale_resnet` function that builds the full shift and log-scale network, using the `Conv2DResidualBlock` class above.\n",
    "\n",
    "* This function takes `input_shape`, `kernel_size` and `l2reg_coeff` as arguments, as well as `residual_blocks`, which is a list of `Conv2DResidualBlock` objects\n",
    "* The function should use the functional API to build the multi-output model\n",
    "* The model should use the `input_shape` in the function argument to set the shape in the Input layer\n",
    "* The inputs should be processed sequentially by the layers contained in the `residual_blocks` list\n",
    "* There should then be a final `Conv2D` layer that processes this output, using the `kernel_size` argument, and $l^2$ kernel regularization using `l2reg_coeff`\n",
    "  * This `Conv2D` layer should have twice as many filters as the input\n",
    "  * It should use `\"SAME\"` padding and have no activation function\n",
    "* The output of this layer should then be split into two equal-sized Tensors along the final channel axis. These two Tensors are the shift and log-scale Tensors, and should each have the same shape as the model input\n",
    "* Finally, you should then apply the `tanh` nonlinearity to the log_scale Tensor\n",
    "* The outputs to the model should be the list of Tensors `[shift, log_scale]`\n",
    "\n",
    "_Hint: use_ `tf.split` _with arguments_ `num_or_size_splits=2, axis=-1` _to create the output Tensors_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def get_shift_and_log_scale_resnet(input_shape, kernel_size, l2reg_coeff, residual_blocks):\n",
    "    \"\"\"\n",
    "    This function should build the CNN shift and log-scale ResNet model according to the \n",
    "    above specification, using the functional API. The model should be multi-output, where\n",
    "    the output Tensors are [shift, log_scale].\n",
    "    Your function should return the model.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    h = inputs\n",
    "    input_filters = input_shape[-1]\n",
    "\n",
    "    for resnet_block in residual_blocks:\n",
    "        h = resnet_block(h)\n",
    "\n",
    "    h = Conv2D(2 * input_filters, kernel_size, padding='same',\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2reg_coeff))(h)\n",
    "    shift, log_scale = tf.split(h, num_or_size_splits=2, axis=-1)\n",
    "    log_scale = tf.math.tanh(log_scale)\n",
    "    return Model(inputs=inputs, outputs=[shift, log_scale], name='conv_resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a shift and log-scale model using your function\n",
    "\n",
    "shift_and_log_scale = get_shift_and_log_scale_resnet((6, 6, 3), (3, 3), 5e-5, \n",
    "                                                     [resnet_block1, resnet_block2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "\n",
    "shift_and_log_scale.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the output shapes are as expected\n",
    "\n",
    "print(shift_and_log_scale(tf.random.normal((1, 6, 6, 3)))[0].shape)\n",
    "print(shift_and_log_scale(tf.random.normal((1, 6, 6, 3)))[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary masks\n",
    "\n",
    "Now that the shift and log-scale model code is complete, you can use it in the implementation of the affine coupling layer. Recall that the affine coupling layer transformations can be rewritten in the following form, using a binary mask $b$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{z} &= b\\odot \\mathbf{x} + (1-b)\\odot(\\mathbf{x}\\odot \\exp(s(b\\odot \\mathbf{x})) + t(b\\odot\\mathbf{x})) & \\text{(forward pass)}\\\\\n",
    "\\mathbf{x} &= b\\odot \\mathbf{z} + (1-b)\\odot((\\mathbf{z}-t(b\\odot\\mathbf{z}))\\odot \\exp(-s(b\\odot \\mathbf{z}))) & \\text{(inverse pass)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The following two functions will be used to create the binary masks in this layer.\n",
    "\n",
    "First, you should complete the following function that builds the channel-wise binary mask. \n",
    "\n",
    "* This function takes a single integer `num_channels` as an input\n",
    "* You can assume that `num_channels` is even\n",
    "* The function should return a rank-3 Tensor with singleton entries for height and width dimensions\n",
    "* In the channel axis, the first `num_channels // 2` entries should be zero, and the final `num_channels // 2` entries should be one\n",
    "* The `dtype` of the returned Tensor should be `tf.float32`\n",
    "* The function should return the binary mask Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def channel_binary_mask(num_channels):\n",
    "    \"\"\"\n",
    "    This function should build and return the channel-wise binary mask as described above,\n",
    "    with zeros for the first half of the channels, and ones for the remainder.\n",
    "    Your function should return the binary mask Tensor.\n",
    "    \"\"\"\n",
    "    mask = np.zeros((num_channels,))\n",
    "    mask[num_channels // 2:] = 1\n",
    "    return tf.reshape(tf.constant(mask, dtype=tf.float32), [1, 1, num_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run your function to see an example channel-wise binary mask\n",
    "\n",
    "channel_binary_mask(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function creates the checkerboard binary mask.\n",
    "\n",
    "* The function takes `shape` as an input, which is a integer tuple of length 2, corresponding to the height and width dimensions\n",
    "* You can assume both height and width dimensions are even integers\n",
    "* The function should return a rank-3 Tensor with a singleton entry in the channel dimension\n",
    "* In the spatial dimensions, the entry at index `[0, 0]` should be zero. The remaining entries should be filled with ones and zeros in a checkerboard pattern\n",
    "* The `dtype` of the returned Tensor should be `tf.float32`\n",
    "* The function should return the binary mask Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def checkerboard_binary_mask(shape):\n",
    "    \"\"\"\n",
    "    This function should build and return the spatial checkerboard binary mask as \n",
    "    described above, with a zero in the [0, 0] entry in the spatial dimensions.\n",
    "    Your function should return the binary mask Tensor.\n",
    "    \"\"\"\n",
    "    height, width = shape[0], shape[1]\n",
    "    height_range = tf.range(height)\n",
    "    width_range = tf.range(width)\n",
    "    height_odd_inx = tf.cast(tf.math.mod(height_range, 2), dtype=tf.bool)\n",
    "    width_odd_inx = tf.cast(tf.math.mod(width_range, 2), dtype=tf.bool)\n",
    "    odd_rows = tf.tile(tf.expand_dims(height_odd_inx, -1), [1, width])\n",
    "    odd_cols = tf.tile(tf.expand_dims(width_odd_inx, 0), [height, 1])\n",
    "    checkerboard_mask = tf.math.logical_xor(odd_rows, odd_cols)\n",
    "    return tf.cast(tf.expand_dims(checkerboard_mask, -1), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to see an example checkerboard binary mask\n",
    "\n",
    "tf.squeeze(checkerboard_binary_mask((6, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affine coupling layer\n",
    "\n",
    "The following is the same class that we implemented in this week's coding tutorial. It will work with either of the binary masks above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the AffineCouplingLayer class\n",
    "\n",
    "class AffineCouplingLayer(tfb.Bijector):\n",
    "\n",
    "    def __init__(self, shift_and_log_scale_fn, mask, **kwargs):\n",
    "        super(AffineCouplingLayer, self).__init__(\n",
    "            forward_min_event_ndims=1, **kwargs)\n",
    "        self.shift_and_log_scale_fn = shift_and_log_scale_fn\n",
    "        self.b = tf.cast(mask, tf.float32)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        t, log_s = self.shift_and_log_scale_fn(x * self.b)\n",
    "        y = self.b * x + (1 - self.b) * (x * tf.exp(log_s) + t)\n",
    "        return y\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        t, log_s = self.shift_and_log_scale_fn(y * self.b)\n",
    "        x = self.b * y + (1 - self.b) * ((y - t) * tf.exp(-log_s))\n",
    "        return x\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        _, log_s = self.shift_and_log_scale_fn(x * self.b)\n",
    "        return tf.reduce_sum(log_s * (1 - self.b), axis=-1)  \n",
    "\n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        _, log_s = self.shift_and_log_scale_fn(y * self.b)\n",
    "        return -tf.reduce_sum(log_s * (1 - self.b), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an affine coupling layer with a checkerboard mask\n",
    "\n",
    "mask = checkerboard_binary_mask((6, 6))\n",
    "affine_coupling_layer = AffineCouplingLayer(shift_and_log_scale, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View an example layer output - look at only one channel dimension for easier viewing\n",
    "\n",
    "output = affine_coupling_layer.forward(tf.ones((1, 6, 6, 3)))\n",
    "print(tf.squeeze(output)[...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, you should find that the masked elements are unchanged.\n",
    "\n",
    "#### Combining the affine coupling layers\n",
    "\n",
    "Recall that the affine coupling layers are combined into groups of 3 or 4 in the RealNVP architecture. Within each group, successive affine coupling layers are applied with alternating masks.\n",
    "\n",
    "You should now complete the following function to build one of these blocks. \n",
    "\n",
    "* The function takes `shift_and_log_scale_fns` and `mask` as an argument\n",
    "* The `shift_and_log_scale_fns` is a list or tuple of shift and log scale objects (as used in the `AffineCouplingLayer` above\n",
    "* The `mask` argument is either a channel-wise or checkerboard mask Tensor\n",
    "* The function should create a new bijector, that consists of successive `AffineCouplingLayer` objects chained together\n",
    "  * The first affine coupling layer should use the mask passed in the `mask` argument\n",
    "  * Following affine coupling layers should use alternating masks (of the same type)\n",
    "* The function should return the bijector object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def affine_coupling_layer_block(shift_and_log_scale_fns, mask):\n",
    "    \"\"\"\n",
    "    This function should build the block of affine coupling layers as described above.\n",
    "    It should use the shift and log scale models passed in the list in successive\n",
    "    affine coupling layers, with alternating masks from one to the next.\n",
    "    Your function should return a bijector object representing the block.\n",
    "    \"\"\"\n",
    "    affine_coupling_layers = []\n",
    "    for shift_and_log_scale in shift_and_log_scale_fns:\n",
    "        affine_coupling_layers.append(AffineCouplingLayer(shift_and_log_scale, mask))\n",
    "        mask = 1 - mask\n",
    "    return tfb.Chain(list(reversed(affine_coupling_layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an affine coupling layer block\n",
    "\n",
    "resnet_block1 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block2 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_1 = get_shift_and_log_scale_resnet((32, 32, 3), (3, 3), 5e-5, \n",
    "                                                     [resnet_block1, resnet_block2])\n",
    "\n",
    "resnet_block3 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block4 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_2 = get_shift_and_log_scale_resnet((32, 32, 3), (3, 3), 5e-5, \n",
    "                                                     [resnet_block3, resnet_block4])\n",
    "\n",
    "resnet_block5 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block6 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_3 = get_shift_and_log_scale_resnet((32, 32, 3), (3, 3), 5e-5, \n",
    "                                                     [resnet_block5, resnet_block6])\n",
    "\n",
    "mask = checkerboard_binary_mask((32, 32))\n",
    "\n",
    "acl_block_1 = affine_coupling_layer_block([shift_and_log_scale_1, \n",
    "                                           shift_and_log_scale_2, \n",
    "                                           shift_and_log_scale_3],\n",
    "                                          mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The squeeze operation\n",
    "\n",
    "In the RealNVP architecture, after an affine coupline layer block with checkerboard masking (as above), there is a squeeze operation, where the spatial dimensions of the layer are divided into $2\\times 2\\times c$ subsquares, and reshaped into $1\\times 1\\times 4c$.\n",
    "\n",
    "The squeezing operation is also a bijective operation. The `_forward`, `_inverse`, `_forward_log_det_jacobian` and `_inverse_log_det_jacobian` methods have been completed for you in the `Squeeze` class below. \n",
    "\n",
    "However, this bijector also changes the shape of its input, and so requires the `_forward_event_shape_tensor` and `_inverse_event_shape_tensor` methods to be implemented. You should now complete the `Squeeze` class implementation by writing these methods.\n",
    "\n",
    "* The `_forward_event_shape_tensor` method takes an `input_shape` argument, and the `_inverse_event_shape_tensor` method takes an `output_shape` argument\n",
    "* The arguments for both methods are a `tf.int32` rank-1 Tensor representing the shape of an input\n",
    "* The `_forward_event_shape_tensor` and `_inverse_event_shape_tensor` methods should return the transformed shape under the `forward` and `inverse` methods respectively\n",
    "* The returned shape should also be a `tf.int32` rank-1 Tensor\n",
    "* The length of `input_shape` and `output_shape` will be at least 3 (since `forward_min_event_ndims=3`), but these methods should account for the possibility that the rank of the inputs/outputs could be greater than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following class. \n",
    "# Make sure to not change the class name or provided methods and signatures.\n",
    "\n",
    "class Squeeze(tfb.Bijector):\n",
    "    \n",
    "    def __init__(self, name='Squeeze', **kwargs):\n",
    "        super(Squeeze, self).__init__(forward_min_event_ndims=3, is_constant_jacobian=True, \n",
    "                                      name=name, **kwargs)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        input_shape = x.shape\n",
    "        height, width, channels = input_shape[-3:]\n",
    "        y = tfb.Reshape((height // 2, 2, width // 2, 2, channels), event_shape_in=(height, width, channels))(x)\n",
    "        y = tfb.Transpose(perm=[0, 2, 1, 3, 4])(y)\n",
    "        y = tfb.Reshape((height // 2, width // 2, 4 * channels),\n",
    "                        event_shape_in=(height // 2, width // 2, 2, 2, channels))(y)\n",
    "        return y\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        input_shape = y.shape\n",
    "        height, width, channels = input_shape[-3:]\n",
    "        x = tfb.Reshape((height, width, 2, 2, channels // 4), event_shape_in=(height, width, channels))(y)\n",
    "        x = tfb.Transpose(perm=[0, 2, 1, 3, 4])(x)\n",
    "        x = tfb.Reshape((2 * height, 2 * width, channels // 4),\n",
    "                        event_shape_in=(height, 2, width, 2, channels // 4))(x)\n",
    "        return x\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        return tf.constant(0., x.dtype)\n",
    "\n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        return tf.constant(0., y.dtype)\n",
    "\n",
    "    def _forward_event_shape_tensor(self, input_shape):\n",
    "        \"\"\"\n",
    "        This method takes a rank-1 tf.int32 input_shape Tensor as input.\n",
    "        It should compute the transformed shape under the forward method.\n",
    "        The transformed shape should be returned as a rank-1 tf.int32 Tensor.\n",
    "        \"\"\"\n",
    "        extra_event_dims = input_shape[:-3]\n",
    "        height, width, channels = input_shape[-3], input_shape[-2], input_shape[-1]\n",
    "        transformed_hwc = tf.stack((height // 2, width // 2, 4 * channels))\n",
    "        return tf.concat((extra_event_dims, transformed_hwc), axis=0)\n",
    "\n",
    "    def _inverse_event_shape_tensor(self, output_shape):\n",
    "        \"\"\"\n",
    "        This method takes a rank-1 tf.int32 input_shape Tensor as input.\n",
    "        It should compute the transformed shape under the inverse method.\n",
    "        The transformed shape should be returned as a rank-1 tf.int32 Tensor.\n",
    "        \"\"\"\n",
    "        extra_event_dims = output_shape[:-3]\n",
    "        height, width, channels = output_shape[-3], output_shape[-2], output_shape[-1]\n",
    "        transformed_hwc = tf.stack((2 * height, 2 * width, channels // 4))\n",
    "        return tf.concat((extra_event_dims, transformed_hwc), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Squeeze bijector\n",
    "\n",
    "squeeze = Squeeze()\n",
    "squeeze(tf.ones((10, 32, 32, 3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the inverse operation\n",
    "\n",
    "squeeze.inverse(tf.ones((10, 4, 4, 96))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiscale architecture\n",
    "\n",
    "You are now ready to bring all of the components together in the complete multiscale architecture. The RealNVP model that we will build will factor out latent variables to downscale the input only once. This model is visualised in the following diagram:\n",
    "\n",
    "<img src=\"figures/realnvp_model.png\" alt=\"RealNVP model\" style=\"width: 800px;\"/>\n",
    "\n",
    "We have already instantiated the first of these affine couple layer blocks above. The following two cells instantiate the remaining two blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the second affine coupling layer block\n",
    "\n",
    "resnet_block7 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block8 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_4 = get_shift_and_log_scale_resnet((16, 16, 12), (3, 3), 5e-5, \n",
    "                                                     [resnet_block7, resnet_block8])\n",
    "\n",
    "resnet_block9 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block10 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_5 = get_shift_and_log_scale_resnet((16, 16, 12), (3, 3), 5e-5, \n",
    "                                                     [resnet_block9, resnet_block10])\n",
    "\n",
    "resnet_block11 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block12 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_6 = get_shift_and_log_scale_resnet((16, 16, 12), (3, 3), 5e-5, \n",
    "                                                     [resnet_block11, resnet_block12])\n",
    "\n",
    "mask = channel_binary_mask(12)\n",
    "\n",
    "acl_block_2 = affine_coupling_layer_block([shift_and_log_scale_4, \n",
    "                                           shift_and_log_scale_5, \n",
    "                                           shift_and_log_scale_6],\n",
    "                                          mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the third affine coupling layer block\n",
    "\n",
    "resnet_block13 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block14 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_7 = get_shift_and_log_scale_resnet((16, 16, 6), (3, 3), 5e-5, \n",
    "                                                     [resnet_block13, resnet_block14])\n",
    "\n",
    "resnet_block15 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block16 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_8 = get_shift_and_log_scale_resnet((16, 16, 6), (3, 3), 5e-5, \n",
    "                                                     [resnet_block15, resnet_block16])\n",
    "\n",
    "resnet_block17 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block18 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_9 = get_shift_and_log_scale_resnet((16, 16, 6), (3, 3), 5e-5, \n",
    "                                                     [resnet_block17, resnet_block18])\n",
    "\n",
    "resnet_block19 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block20 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_10 = get_shift_and_log_scale_resnet((16, 16, 6), (3, 3), 5e-5, \n",
    "                                                        [resnet_block19, resnet_block20])\n",
    "\n",
    "mask = checkerboard_binary_mask((16, 16))\n",
    "\n",
    "acl_block_3 = affine_coupling_layer_block([shift_and_log_scale_7, \n",
    "                                           shift_and_log_scale_8, \n",
    "                                           shift_and_log_scale_9,\n",
    "                                           shift_and_log_scale_10],\n",
    "                                          mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now implement the multiscale architecture in the following subclassed bijector. This bijector should be constructed to be able to operate on a batch of Tensors of shape `(H, W, C)`, with the only assumption being that `H` and `W` are both even.\n",
    "\n",
    "* The initializer takes the three affine coupling layer blocks that are part of the above architecture:\n",
    "  * `acl_block_1` is a block with 3 affine coupling layers with checkerboard masking\n",
    "  * `acl_block_2` is a block with 3 affine coupling layers with channel masking\n",
    "  * `acl_block_3` is n block with 4 affine coupling layers with checkerboard masking\n",
    "* You should implement the `_forward`, `_inverse`, `_forward_log_det_jacobian`, `_inverse_log_det_jacobian`, `_forward_event_shape_tensor` and `_inverse_event_shape_tensor` methods\n",
    "* The forward transformation should operate on the inputs as depicted above:\n",
    "  * It should pass the inputs through the first ACL block, a `Squeeze` operation, and then the second ACL block\n",
    "  * It should then split the Tensor in half along the channel axis\n",
    "  * The first half of the channel dimesions should be used as latent variables. Call this $\\mathbf{z}^{(1)}$\n",
    "  * The second half of the channel dimensions (call this $\\mathbf{h}^{(1)}$) should be further processed through the third ACL block to produce $\\mathbf{z}^{(2)}$\n",
    "  * The final latent variable $\\mathbf{z} = (\\mathbf{z}^{(1)}, \\mathbf{z}^{(2)})$ should concatenate along the channel dimension. This should be returned by the `_forward` method\n",
    "* The `_inverse` method should perform precisely the inverse of the `_forward` method\n",
    "* The `_forward_log_det_jacobian` method should compute the log determinant of the Jacobian of the forward transformation, using the `forward_log_det_jacobian` method of each ACL block bijector\n",
    "* The `_inverse_log_det_jacobian` method should compute the log determinant of the Jacobian of the inverse transformation, using the `inverse_log_det_jacobian` method of each ACL block bijector\n",
    "* Since this bijector changes the shape of the input, it is necessary to complete `_forward_event_shape_tensor` and `_inverse_event_shape_tensor` methods\n",
    "  * Note that these methods will be the same as for the `Squeeze` bijector above\n",
    "  \n",
    "_Hint: use_ `tf.split` _and_ `tf.concat` _to factor out (and recombine) latent variables in the forward and inverse passes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following class. \n",
    "# Make sure to not change the class name or provided methods and signatures.\n",
    "\n",
    "class RealNVPMultiScale(tfb.Bijector):\n",
    "    \n",
    "    def __init__(self, acl_block_1, acl_block_2, acl_block_3, **kwargs):\n",
    "        super(RealNVPMultiScale, self).__init__(forward_min_event_ndims=3, **kwargs)\n",
    "        self.acl_block_1 = acl_block_1\n",
    "        self.acl_block_2 = acl_block_2\n",
    "        self.acl_block_3 = acl_block_3\n",
    "        self.squeeze = Squeeze()\n",
    "\n",
    "    def _forward(self, x):\n",
    "        \"\"\"\n",
    "        This function computes the forward transformation as described above.\n",
    "        It takes an input image batch x, and returns a latent variable batch z.\n",
    "        \"\"\"\n",
    "        h = self.acl_block_1.forward(x)\n",
    "        h = self.squeeze.forward(h)\n",
    "        h = self.acl_block_2.forward(h)\n",
    "        z1, h1 = tf.split(h, 2, axis=-1)\n",
    "        z2 = self.acl_block_3.forward(h1)\n",
    "        return tf.concat([z1, z2], axis=-1)\n",
    "        \n",
    "    def _inverse(self, z):\n",
    "        \"\"\"\n",
    "        This function computes the inverse transformation as described above.\n",
    "        It takes a latent variable batch z, and returns an input image batch x.\n",
    "        \"\"\"\n",
    "        z1, z2 = tf.split(z, 2, axis=-1)\n",
    "        h1 = self.acl_block_3.inverse(z2)\n",
    "        h = tf.concat([z1, h1], axis=-1)\n",
    "        h = self.acl_block_2.inverse(h)\n",
    "        h = self.squeeze.inverse(h)\n",
    "        return self.acl_block_1.inverse(h)\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        \"\"\"\n",
    "        This function computes the log determinant of the Jacobian of the\n",
    "        forward transformation as described above.\n",
    "        It takes an input image batch x, and returns a Tensor with the event dimensions reduced out.\n",
    "        \"\"\"\n",
    "        log_det1_1 = self.acl_block_1.forward_log_det_jacobian(x, event_ndims=3)\n",
    "        h = self.acl_block_1.forward(x)\n",
    "        h = self.squeeze.forward(h)\n",
    "        log_det1_2 = self.acl_block_2.forward_log_det_jacobian(h, event_ndims=3)\n",
    "        h = self.acl_block_2.forward(h)\n",
    "        _, h1 = tf.split(h, 2, axis=-1)\n",
    "        log_det2 = self.acl_block_3.forward_log_det_jacobian(h1, event_ndims=3)\n",
    "        return log_det1_1 + log_det1_2 + log_det2\n",
    "\n",
    "    def _inverse_log_det_jacobian(self, z):\n",
    "        \"\"\"\n",
    "        This function computes the log determinant of the Jacobian of the\n",
    "        inverse transformation as described above.\n",
    "        It takes a latent variable batch z, and returns a Tensor with the event dimensions reduced out.\n",
    "        \"\"\"\n",
    "        z1, z2 = tf.split(z, 2, axis=-1)\n",
    "        log_det2 = self.acl_block_3.inverse_log_det_jacobian(z2, event_ndims=3)\n",
    "        h1 = self.acl_block_3.inverse(z2)\n",
    "        h = tf.concat([z1, h1], axis=-1)\n",
    "        log_det1_2 = self.acl_block_2.inverse_log_det_jacobian(h, event_ndims=3)\n",
    "        h = self.acl_block_2.inverse(h)\n",
    "        h = self.squeeze.inverse(h)\n",
    "        log_det1_1 = self.acl_block_1.inverse_log_det_jacobian(h, event_ndims=3)\n",
    "        return log_det1_1 + log_det1_2 + log_det2\n",
    "\n",
    "    def _forward_event_shape_tensor(self, input_shape):\n",
    "        \"\"\"\n",
    "        This method should be the same as for the Squeeze bijector.\n",
    "        \"\"\"\n",
    "        extra_event_dims = input_shape[:-3]\n",
    "        height, width, channels = input_shape[-3], input_shape[-2], input_shape[-1]\n",
    "        transformed_hwc = tf.stack((height // 2, width // 2, 4 * channels))\n",
    "        return tf.concat((extra_event_dims, transformed_hwc), axis=0)\n",
    "\n",
    "    def _inverse_event_shape_tensor(self, output_shape):\n",
    "        \"\"\"\n",
    "        This method should be the same as for the Squeeze bijector.\n",
    "        \"\"\"\n",
    "        extra_event_dims = output_shape[:-3]\n",
    "        height, width, channels = output_shape[-3], output_shape[-2], output_shape[-1]\n",
    "        transformed_hwc = tf.stack((2 * height, 2 * width, channels // 4))\n",
    "        return tf.concat((extra_event_dims, transformed_hwc), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the RealNVP model\n",
    "\n",
    "realnvp = RealNVPMultiScale(acl_block_1, acl_block_2, acl_block_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing bijector\n",
    "\n",
    "We will also preprocess the image data before sending it through the RealNVP model. To do this, for a Tensor $\\mathbf{x}$ of pixel values in $[0, 1]^D$, we transform $\\mathbf{x}$ according to the following (all operations performed elementwise):\n",
    "\n",
    "$$\n",
    "T(\\mathbf{x}) = \\text{logit}\\left(\\alpha + (1 - 2\\alpha)\\mathbf{x}\\right),\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is a parameter, and the logit function is the inverse of the sigmoid function, which is given by \n",
    "\n",
    "$$\n",
    "\\text{logit}(p) = \\log (p) - \\log (1 - p).\n",
    "$$\n",
    "\n",
    "You should now complete the following function to construct this bijector from in-built bijectors from the bijectors module.\n",
    "\n",
    "* The function takes the parameter `alpha` as an input, which you can assume to take a small positive value ($\\ll0.5$)\n",
    "* The function should construct and return a bijector that computes $T(\\mathbf{x})$ in the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def get_preprocess_bijector(alpha):\n",
    "    \"\"\"\n",
    "    This function should create a chained bijector that computes the \n",
    "    transformation T in equation (7) above.\n",
    "    This can be computed using in-built bijectors from the bijectors module.\n",
    "    Your function should then return the chained bijector.\n",
    "    \"\"\"\n",
    "    scale = tfb.Scale(1 - 2*alpha)\n",
    "    shift = tfb.Shift(alpha)\n",
    "    logit = tfb.Invert(tfb.Sigmoid())\n",
    "    return tfb.Chain([logit, shift, scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the preprocess bijector\n",
    "\n",
    "preprocess = get_preprocess_bijector(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the RealNVP model\n",
    "\n",
    "We will use the following model class to help with the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper custom model for training\n",
    "\n",
    "class RealNVPModel(Model):\n",
    "\n",
    "    def __init__(self, realnvp_multiscale, preprocess, **kwargs):\n",
    "        super(RealNVPModel, self).__init__(**kwargs)\n",
    "        self.preprocess = preprocess\n",
    "        self.realnvp_multiscale = realnvp_multiscale\n",
    "        self.bijector = tfb.Chain([self.realnvp_multiscale, self.preprocess])\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        output_shape = self.bijector(tf.expand_dims(tf.zeros(input_shape[1:]), axis=0)).shape\n",
    "        self.base = tfd.Independent(tfd.Normal(loc=tf.zeros(output_shape[1:]), scale=1.),\n",
    "                                    reinterpreted_batch_ndims=3)\n",
    "        self._bijector_variables = (\n",
    "            list(self.bijector.variables))\n",
    "        self.flow = tfd.TransformedDistribution(\n",
    "            distribution=self.base,\n",
    "            bijector=tfb.Invert(self.bijector),\n",
    "        )\n",
    "        super(RealNVPModel, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        return self.flow\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        sample = self.base.sample(batch_size)\n",
    "        return self.bijector.inverse(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the RealNVPModel class\n",
    "\n",
    "realnvp_model = RealNVPModel(realnvp, preprocess)\n",
    "realnvp_model.build((1, 32, 32, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the model's `call` method returns the `TransformedDistribution` object. Also, we have set up our datasets to return the input image twice as a 2-tuple. This is so we can train our model with negative log-likelihood as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the negative log-likelihood loss function\n",
    "\n",
    "def nll(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "realnvp_model.compile(loss=nll, optimizer=optimizer)\n",
    "realnvp_model.fit(train_ds, validation_data=valid_ds, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the model\n",
    "\n",
    "n_images = 12\n",
    "samples = realnvp_model.sample(n_images).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the samples\n",
    "\n",
    "f, axs = plt.subplots(2, n_images // 2, figsize=(17, 6))\n",
    "for k, image in enumerate(samples):\n",
    "    i = k % 2\n",
    "    j = k // 2\n",
    "    axs[i, j].imshow(np.clip(image, 0., 1.))\n",
    "    axs[i, j].axis('off')\n",
    "f.subplots_adjust(wspace=0.03, hspace=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on completing this week's assignment! In this assignment you have developed a full implementation of the RealNVP architecture, including the affine coupling layers with channel-wise and checkerboard masking, CNN ResNet networks for the shift and log scale functions, the squeeze operation and multiscale architecture. For optimal performance, the model should be larger and trained for longer. The architecture in the original paper also contains some additional features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
